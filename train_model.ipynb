{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "MF4bweVsXU57"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pwDBM7AUblHg",
        "outputId": "ba1c1852-3a46-4ed9-ab29-3275c7c3c88f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2bc68562-6a93-4441-8c59-8f0e9213be44\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2bc68562-6a93-4441-8c59-8f0e9213be44\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tweets.csv to Tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Tweets.csv dataset\n",
        "df = pd.read_csv('Tweets.csv')"
      ],
      "metadata": {
        "id": "2iGUBH0sXaln"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlADaKxlSE_d",
        "outputId": "79a96f70-9904-4087-c8e4-c958b0645759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
            "0  570306133677760513           neutral                        1.0000   \n",
            "1  570301130888122368          positive                        0.3486   \n",
            "2  570301083672813571           neutral                        0.6837   \n",
            "3  570301031407624196          negative                        1.0000   \n",
            "4  570300817074462722          negative                        1.0000   \n",
            "\n",
            "  negativereason  negativereason_confidence         airline  \\\n",
            "0            NaN                        NaN  Virgin America   \n",
            "1            NaN                     0.0000  Virgin America   \n",
            "2            NaN                        NaN  Virgin America   \n",
            "3     Bad Flight                     0.7033  Virgin America   \n",
            "4     Can't Tell                     1.0000  Virgin America   \n",
            "\n",
            "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
            "0                    NaN     cairdin                 NaN              0   \n",
            "1                    NaN    jnardino                 NaN              0   \n",
            "2                    NaN  yvonnalynn                 NaN              0   \n",
            "3                    NaN    jnardino                 NaN              0   \n",
            "4                    NaN    jnardino                 NaN              0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0                @VirginAmerica What @dhepburn said.         NaN   \n",
            "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
            "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
            "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
            "\n",
            "               tweet_created tweet_location               user_timezone  \n",
            "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
            "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
            "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
            "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
            "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names and shape\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "\n",
        "# Check sentiment distribution\n",
        "print(df['airline_sentiment'].value_counts())\n",
        "\n",
        "# Example tweet\n",
        "print(df['text'][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVg4w3nhcf64",
        "outputId": "4c2ae833-c03e-4bb5-99d3-0f6d6c902c1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
            "       'negativereason', 'negativereason_confidence', 'airline',\n",
            "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
            "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
            "       'tweet_location', 'user_timezone'],\n",
            "      dtype='object')\n",
            "(14640, 15)\n",
            "airline_sentiment\n",
            "negative    9178\n",
            "neutral     3099\n",
            "positive    2363\n",
            "Name: count, dtype: int64\n",
            "@VirginAmerica What @dhepburn said.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords   # Natural Language Toolkit for text processing\n",
        "\n",
        "nltk.download('stopwords')    # list of common words (like “the”, “and”, “is”) often removed from text, this downloads the English stopwords list from NLTK\n",
        "stop_words = set(stopwords.words('english'))   # Loads the English stopwords into a set for fast lookup when filtering text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # remove URLs\n",
        "    text = re.sub(r'@\\w+|\\#', '', text)  # remove mentions and hashtags\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # remove punctuations\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])  # remove stopwords (\"the\", \"and\",...)\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)   # clean_text function applied to each row in the text column of the DataFrame and creates a new column clean_text with the results\n",
        "print(df['clean_text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEvp9hfqc9F4",
        "outputId": "ea649869-6b04-4e44-cbc1-91f73738630c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                 said\n",
            "1        plus youve added commercials experience tacky\n",
            "2         didnt today must mean need take another trip\n",
            "3    really aggressive blast obnoxious entertainmen...\n",
            "4                                 really big bad thing\n",
            "Name: clean_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Sentiment Labels\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['sentiment_label'] = le.fit_transform(df['airline_sentiment'])   # fit_transform() reads all unique values in df['airline_sentiment'] and assigns them numbers 0 for negative, 1 for neutral, and 2 for positive which are now saved in a new column called sentiment_label\n",
        "print(le.classes_)  # ['negative', 'neutral', 'positive']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIVsFNmpsyDl",
        "outputId": "ef44cc27-c445-4da6-c0d4-0a6490a86973"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative' 'neutral' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['clean_text']      # input features — cleaned tweet texts\n",
        "y = df['sentiment_label'] # target labels — encoded sentiment values (0, 1, 2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)\n"
      ],
      "metadata": {
        "id": "Ex5_dsiytKJ7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the Text (TF-IDF)\n",
        "# TF-IDF — Term Frequency–Inverse Document Frequency\n",
        "# TF (Term Frequency): how often a word appears in a document\n",
        "# IDF (Inverse Document Frequency): how rare the word is across all documents\n",
        "# Common words (like \"the\", \"and\") appear in many documents and get lower scores\n",
        "# Uncommon but meaningful words get higher scores\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# This imports a tool that converts text into numeric feature vectors using the TF-IDF method\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "# Only keeps the top 5,000 most important words (based on TF-IDF score)\n",
        "# This reduces dimensionality and speeds up training\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "# This fit the vectorizer and transform training data\n",
        "# Learns the vocabulary and computes TF-IDF scores from the training texts\n",
        "# Converts the training text into spare matrix of shape (samples, 5000)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "# Transform test data by applying the same vocabulary (from training) to the test set\n",
        "# Ensures that the training and test data have the same structure\n",
        "\n",
        "print(X_train_tfidf.shape)  # (number_of_samples, 5000)\n",
        "print(X_test_tfidf.shape)   # (number_of_samples, 5000)\n",
        "# This shows the dimensions of the TF-IDF matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhgV2eF9yBQK",
        "outputId": "bfd3b2cb-d3b7-4b76-9b7e-3060e501cf2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11712, 5000)\n",
            "(2928, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression   # Best for binary and multiclass classificaion\n",
        "from sklearn.metrics import classification_report, accuracy_score   # Import evaluation metrics\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)  # max_iter=1000 increases the number of training iterations to help the model converge (default is 100)\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqHf4MyU5ipN",
        "outputId": "1408cb13-9293-44e1-b4ed-2654bf779d03"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Accuracy: 0.7827868852459017\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.94      0.87      1835\n",
            "     neutral       0.66      0.49      0.56       620\n",
            "    positive       0.82      0.56      0.67       473\n",
            "\n",
            "    accuracy                           0.78      2928\n",
            "   macro avg       0.76      0.66      0.70      2928\n",
            "weighted avg       0.78      0.78      0.77      2928\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tweets = [\"Flight delayed again. Terrible experience.\",\n",
        "              \"Thanks for the great service!\",\n",
        "              \"It was okay, nothing special.\",\n",
        "              \"not sure about what I could say, not bad and not too impressive either\",\n",
        "              \"I wish I could use another classroom\",\n",
        "              \"Mike was gonna come later today, try hold on\",\n",
        "              \"streamlit has their own UI designed already, looks easy to use\"]\n",
        "\n",
        "new_cleaned = [clean_text(tweet) for tweet in new_tweets]\n",
        "new_tfidf = tfidf.transform(new_cleaned)\n",
        "predictions = lr.predict(new_tfidf)\n",
        "\n",
        "print(predictions)  # outputs: [0, 2, 1] or similar\n",
        "print(le.inverse_transform(predictions))  # to get original labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIMGQpmyBDqE",
        "outputId": "28e298ad-a05f-4a10-bca2-3a7948a55666"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 0 0 1 0 0]\n",
            "['negative' 'positive' 'negative' 'negative' 'neutral' 'negative'\n",
            " 'negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save files\n",
        "import pickle\n",
        "\n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(lr, f)\n",
        "\n",
        "with open(\"tfidf.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tfidf, f)\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# Download from Colab\n",
        "from google.colab import files\n",
        "files.download(\"model.pkl\")\n",
        "files.download(\"tfidf.pkl\")\n",
        "files.download(\"label_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mHrK2fNt0TMi",
        "outputId": "28c8ab46-4e6b-4c2d-d1f9-3101d455e3ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d1d61d5-64ce-4360-8764-d4b67d5a3c68\", \"model.pkl\", 120754)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f9b6ee66-2b2a-4305-ac20-35a8559b2a4b\", \"tfidf.pkl\", 181940)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e069e8ed-03d7-490f-adf1-51f09f7773fc\", \"label_encoder.pkl\", 275)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save clean.py file\n",
        "\n",
        "%%writefile clean.py\n",
        "def clean_text(text):\n",
        "    # your cleaning logic here\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhCRSBna1SLh",
        "outputId": "72af3d6f-b52d-42f8-b487-c4f35470bd86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing clean.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"clean.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qMd3JN_H1cKG",
        "outputId": "6f4ce592-38a7-4f9d-ce9b-05961601fce7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c8b3905c-81bd-4933-918b-4e72b5664a8b\", \"clean.py\", 77)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}